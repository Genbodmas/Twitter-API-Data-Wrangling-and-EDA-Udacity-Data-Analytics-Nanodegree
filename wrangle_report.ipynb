{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To gather data from the different sources \n",
    "- To assess these data and check for quality and tidyness issue\n",
    "- To clean these identified issues, merge and produce a clean data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different data was gathered in this stage, all from three different data sources\n",
    "- Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv): <br>\n",
    "    This data was already given to be downloaded locally. This was loaded into the notebook with pandas read_csv command\n",
    "\n",
    "-  Tweet image prediction (image_predictions.tsv): <br>\n",
    "    This data contains the tweet image predictions of the dog. It is hosted on Udacity's servers and was to be downloaded using  the python  Requests library, as the url link of the data was given\n",
    "    \n",
    "- Additional data via the Twitter API (tweet_json.txt): <br>\n",
    "    This data requires me to gather each tweet's retweet count and favorite (\"like\") count at the minimum. Using the tweet IDs in the WeRateDogs Twitter archive, the Twitter API was queried for each tweet's JSON data using Python's Tweepy library and each tweet's was stored in the form of a JSON data called tweet_json.txt file. <br>\n",
    "    \n",
    "    To query the Twitter API, this process required me to have a Twitter elevated account authentication details, which i applied for and was approved in a couple of hours\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stage, i applied both visual and programmatic assessment to identify and list our various quality and tidyness issue in the data. <br>\n",
    "These are:\n",
    "\n",
    "### Quality Issues\n",
    "##### `twitter_archive` table\n",
    "1. tweet text column should only contain the text\n",
    "\n",
    "2. Some entries are not original tweets (replies and retweets)\n",
    "\n",
    "3. Drop columns that are essentially empty\n",
    "\n",
    "4. Timestamp column is not in appropriate format\n",
    "\n",
    "5. Ratings not extracted correctly (decimal ratings)\n",
    "\n",
    "6. Rating_numerator column contain outlier values (1776, 204,0)\n",
    "\n",
    "7. Ratings_denominator column has values more or less than 10\n",
    "\n",
    "8. Some dogs name were incorrectly entered (a, an, the)\n",
    "\n",
    "##### `image_pred` table\n",
    "9. Get the final prediction of the dog breed from the two predicted values\n",
    "   \n",
    "10.  Capitalize each dog name\n",
    "\n",
    "##### `tweet_rem` table\n",
    "11. rename 'id' column to 'tweet_id'\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "1. Dog stages should be combined to one column \n",
    "\n",
    "2. Merge three DataFrame to One Master dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Quality Issue 1`: tweet text column should only contain the text\n",
    "    The main text column contained additional text and 'dirt' like the hashtag, tweetlink. ratings which have already been extracted into their individual columns <br>\n",
    "    \n",
    "    __Cleaning solution__: Regular Expresion was applied to clean these 'dirts', the numbers was looked up and removed, as well as hashtags and hyperlink\n",
    "    \n",
    "    \n",
    "- `Quality Issue 2`: Some entries are not original tweets (replies and retweets)\n",
    "    We have some texts in the column that are retweets or replies, and we dont want the in the dataframe as per the project specification. .They are indicated by those rows having values in retweeted_status_id and in_reply_to_status_id\n",
    "    \n",
    "    __Cleaning Solution__: Identify rows with values in retweeted_status_id and in_reply_to_status_id column and drop them\n",
    "        \n",
    "       \n",
    "- `Quality Issue 3`: Drop columns that are essentially empty\n",
    "    This problem defines columns that are completely empty or not of any importance\n",
    "    \n",
    "    __Cleaning Solution__: pandas 'drop' command was used to drop these columns\n",
    "    \n",
    "    \n",
    "- `Quality Issue 4`: Timestamp column is not in appropriate format\n",
    "    This issue defines that the timestamp column was not in its appropriate column\n",
    "    \n",
    "    __Cleaning Solution__:twitter_archive timestamp column datatype was changed to datetime64 using pandas 'to_datetime' command\n",
    "    \n",
    "    \n",
    "- `Quality Issue 5`: Ratings not extracted correctly (decimal ratings)\n",
    "    Row 45 was rated 13.5 but 5 was recorded\n",
    "    \n",
    "    __Cleaning Solution__: Correctly extract the decimal with regex and replace in the original dataframe\n",
    "   \n",
    "   \n",
    "- `Quality Issue 6`: Rating_numerator column contain arbitrary values (1776, 204,0)\n",
    "    By definition, no rating number should be above 15 at most\n",
    "    \n",
    "    __Cleaning Solution__: All ratings above 15 was replaced with the mean of the ratings (13)\n",
    "\n",
    "\n",
    "- `Quality Issue 7`: Ratings_denominator column has values more or less than 10\n",
    "    Also, By definition, no denominator values should be less or more than zero, but rather exactly zero.\n",
    "    \n",
    "    __Cleaning Solution__: All denominator ratings not 10 was replaced with 10\n",
    "\n",
    "\n",
    "- `Quality Issue 8`:Some dogs name were incorrectly entered\n",
    "    Some dog have names as \"a\",\"an\" and \"the\" we would be changing them to none\n",
    "    \n",
    "    __Cleaning Solution__: All dog with names \"A\", \"AN\", and \"THE\" was replaced with \"None\"\n",
    "    \n",
    "    \n",
    "- `Quality Issue 9`: Get the final prediction of the dog breed from the two predicted values\n",
    "    We have three dog image predictions in the image pred table (p1, p2 and p3), and To get the final prediction ,I compared the three columns and print out the one with the highest confidence, before We finally cleaning off the other information not needed on the table\n",
    "    \n",
    "    __Cleaning Solution__: Final Prediction column was created by comparing the three probability columns (p1_conf, p2_conf and p3_conf and return the highest) <br>\n",
    "      It was found that the First prediction (p1_conf) was the highest prediction columns of the three\n",
    "      Some values of P1 with high prediction apprears to be False (i.e They are not dog images), such predictions were identified and ropped from the table\n",
    "\n",
    "\n",
    "\n",
    "- `Quality Issue 10`: Capitalize each dog name\n",
    "    Each dogs name needs to be capitalized as per english definition of a Noun\n",
    "    \n",
    "    __Cleaning Solution__: pandas capitalize command was applied\n",
    "   \n",
    "   \n",
    "- `Quality Isssue 11`: rename 'id' column to 'tweet_id'\n",
    "    The connecting identifier column of the three tables (tweet_id) have to be spelt the same or else merging would not occur\n",
    "    \n",
    "    __Cleaning Solution__: pandas rename command was used to rename 'id' column to 'tweet_id'\n",
    "\n",
    "\n",
    "- `Tidiness Issue 1`: Dog stages should be combined to one column\n",
    "    Each dogs type needs to form a single column, and the previous columns needs to be cleaned off the dtaframe <br>\n",
    "    \n",
    "    __Cleaning solution__: Every \"None\" was converted to empty string for easy conversion, then the four columns were merged into one.\n",
    "    The previous columns were also dropped\n",
    "    \n",
    "    \n",
    "- `Tidiness Issue 2`: Merge three DataFrame to One Master dataFrame\n",
    "    The three assessed and cleaned dataframe needs to be merged together to create a master dataframe\n",
    "    \n",
    "    __Cleaning Solution__: The three dataframes (tables) were merged on a common key ('tweet_id') to create one master dataframe ready for cleaning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the Wrangling process is a cleaned, assessed and merged data which was saved to csv and ready for analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
